{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y33e6ELCjV--"
      },
      "source": [
        "# **Data Engineering ETL: HM Land Registry Price Paid Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0KMiQX7j9qF"
      },
      "source": [
        "**Installing neccesary libraries**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-npqZrcp7Gm",
        "outputId": "fbc8a428-54c8-4942-a359-d6c5bde4d77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3==1.26.90\n",
            "  Downloading boto3-1.26.90-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.90 (from boto3==1.26.90)\n",
            "  Downloading botocore-1.29.147-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3==1.26.90)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3==1.26.90)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.90->boto3==1.26.90) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.90->boto3==1.26.90) (1.26.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.90->boto3==1.26.90) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.26.90 botocore-1.29.147 jmespath-1.0.1 s3transfer-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3==1.26.90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s00W7wG5zs4C",
        "outputId": "edb50a9c-760a-4e79-db18-165bcb5ca069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting s3fs\n",
            "  Downloading s3fs-2023.5.0-py3-none-any.whl (28 kB)\n",
            "Collecting aiobotocore~=2.5.0 (from s3fs)\n",
            "  Downloading aiobotocore-2.5.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec==2023.5.0 (from s3fs)\n",
            "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.29.77,>=1.29.76 (from aiobotocore~=2.5.0->s3fs)\n",
            "  Downloading botocore-1.29.76-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore~=2.5.0->s3fs) (1.14.1)\n",
            "Collecting aioitertools>=0.5.1 (from aiobotocore~=2.5.0->s3fs)\n",
            "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (1.26.15)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (1.16.0)\n",
            "Installing collected packages: multidict, fsspec, frozenlist, async-timeout, aioitertools, yarl, botocore, aiosignal, aiohttp, aiobotocore, s3fs\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.4.0\n",
            "    Uninstalling fsspec-2023.4.0:\n",
            "      Successfully uninstalled fsspec-2023.4.0\n",
            "  Attempting uninstall: botocore\n",
            "    Found existing installation: botocore 1.29.147\n",
            "    Uninstalling botocore-1.29.147:\n",
            "      Successfully uninstalled botocore-1.29.147\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "boto3 1.26.90 requires botocore<1.30.0,>=1.29.90, but you have botocore 1.29.76 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiobotocore-2.5.0 aiohttp-3.8.4 aioitertools-0.11.0 aiosignal-1.3.1 async-timeout-4.0.2 botocore-1.29.76 frozenlist-1.3.3 fsspec-2023.5.0 multidict-6.0.4 s3fs-2023.5.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install s3fs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C74-9ZcSBoV7",
        "outputId": "246e868e-fac7-43ee-d47a-bcb9759f98b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting apache_beam\n",
            "  Downloading apache_beam-2.48.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod<2.0,>=1.7 (from apache_beam)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4.0 (from apache_beam)\n",
            "  Downloading orjson-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache_beam)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache_beam)\n",
            "  Downloading fastavro-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache_beam)\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.54.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache_beam)\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.21.0)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.22.4)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache_beam)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache_beam)\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.22.2)\n",
            "Requirement already satisfied: protobuf<4.24.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2022.10.31)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.5.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache_beam)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (9.0.0)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache_beam)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache_beam) (3.0.9)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache_beam)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.4)\n",
            "Building wheels for collected packages: crcmod, dill, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=37108 sha256=48b60071323057122acb4645bd5e151ffb8539e9d28ed32ed7e2432ca416b13e\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=58f6a695c7de5af3c2c64bfe55d8eb900fca98e2881dee2d2377503633fe64c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=2fed44b624f83945ec94cd927856dcb705515bcbdc7a1bdcdc231ed313e73a4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill docopt\n",
            "Installing collected packages: docopt, crcmod, zstandard, orjson, objsize, fasteners, fastavro, dnspython, dill, pymongo, hdfs, apache_beam\n",
            "Successfully installed apache_beam-2.48.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.3.0 docopt-0.6.2 fastavro-1.7.4 fasteners-0.18 hdfs-2.7.0 objsize-0.6.1 orjson-3.9.0 pymongo-4.3.3 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install apache_beam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RM_feHyvlxT"
      },
      "source": [
        "\n",
        "\n",
        " **Code blocks begin**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FroBnJNSzLKd"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import apache_beam as beam\n",
        "import json\n",
        "from apache_beam.io import ReadFromText\n",
        "import re\n",
        "import urllib.parse\n",
        "from apache_beam.options import pipeline_options\n",
        "from apache_beam.io.mongodbio import WriteToMongoDB\n",
        "\n",
        "#Importing all the neccesary libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.parse\n",
        "\n",
        "# URL encode the username and password\n",
        "username = urllib.parse.quote_plus(\"<your_username>\")\n",
        "password = urllib.parse.quote_plus(\"<your_password>\")\n",
        "\n",
        "# Create the connection URI with the encoded username and password\n",
        "connection_uri = f\"mongodb+srv://{username}:{password}@clustervk.ofeimsy.mongodb.net/\"\n",
        "\n",
        "#You can fetch this connection string from MongoDB Atlas or your local Compass DB"
      ],
      "metadata": {
        "id": "r3x2_EWXqFn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzLOM6xGknoU"
      },
      "source": [
        "Initialising pipeline options for reading the Tranactions data csv file stored on AWS S3 Bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzWllWSuYayj"
      },
      "outputs": [],
      "source": [
        " options_aws = pipeline_options.S3Options([\n",
        "                \"--s3_region_name=<your_region>\",\n",
        "                \"--s3_access_key_id=<your_key_id>\",\n",
        "                \"--s3_secret_access_key=<your_key>\"\n",
        "            ])\n",
        " #Pipeline options to connect to S3 bucket and Extract csv data "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforms"
      ],
      "metadata": {
        "id": "tKnTEKtitPPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform to split indivual fields of the data"
      ],
      "metadata": {
        "id": "zUrPx5BPCpNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_csv_line(line):\n",
        "    pattern = r'\"([^\"]*)\"'\n",
        "    columns = re.findall(pattern, line)\n",
        "    return columns\n",
        "\n",
        "#Some on the columns have comma in them, forcing us to use regular expression to parse instead of split() method    "
      ],
      "metadata": {
        "id": "-gawRLF9Buyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ParDo transform to generate key value pairs to later aggregate the data for each property"
      ],
      "metadata": {
        "id": "kfQJkNzYCvYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExtractInfo(beam.DoFn):\n",
        "    def process(self, data):\n",
        "        transaction_id = data[0].strip('\"')\n",
        "        price = int(data[1].strip('\"'))\n",
        "        date_of_transfer = data[2].strip('\"')\n",
        "        postcode = data[3].strip('\"')\n",
        "        property_type = data[4].strip('\"')\n",
        "        old_new = data[5].strip('\"')\n",
        "        duration = data[6].strip('\"')\n",
        "        paon = data[7].strip('\"').replace(\",\", \"\")\n",
        "        saon = data[8].strip('\"').replace(\",\", \"\")\n",
        "        street = data[9].strip('\"').replace(\",\", \"\")\n",
        "        locality = data[10].strip('\"').replace(\",\", \"\")\n",
        "        town_city = data[11].strip('\"').replace(\",\", \"\")\n",
        "        district = data[12].strip('\"')\n",
        "        county = data[13].strip('\"')\n",
        "        ppd_category_type = data[14].strip('\"')\n",
        "        record_status = data[15].strip('\"')\n",
        "\n",
        "        # Generate property key\n",
        "        property_key = ','.join([paon, saon, street, locality, postcode.split(' ')[0]])\n",
        "\n",
        "        #This is the best logic to generate key for identifiying properties uniquely. \n",
        "\n",
        "        return [(property_key, {\n",
        "            'Tran_uid': transaction_id,\n",
        "            'Price': price,\n",
        "            'Date_tran': date_of_transfer,\n",
        "            'Postcode': postcode,\n",
        "            'PType': property_type,\n",
        "            'Old_New': old_new,\n",
        "            'Duration': duration,\n",
        "            'Town_City': town_city,\n",
        "            'District': district,\n",
        "            'County': county,\n",
        "            'PPD_cat': ppd_category_type,\n",
        "            'Record_stat': record_status\n",
        "        })]"
      ],
      "metadata": {
        "id": "CWjioXtyCRp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoZHiHZTpHkX"
      },
      "source": [
        "Based on running tests and analysing the Dataset, i concluded to uniquely identify each property based on the combition of PAON,SAON,Street,Locality and first half of the postcode. More info: check Repo Readme"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FormatInfo(beam.DoFn):\n",
        "    def process(self, data):\n",
        "        property_id = propkeyid_gen(data[0].split(',')[-1])  # Generate property ID\n",
        "\n",
        "        property_data = {\n",
        "            'PropertyID': property_id,\n",
        "            'Postcode': data[1][-1]['Postcode'],\n",
        "            'PAON': data[0].split(',')[0],\n",
        "            'SAON': data[0].split(',')[1],\n",
        "            'Street': data[0].split(',')[2],\n",
        "            'Locality': data[0].split(',')[3],\n",
        "            'TownCity': data[1][-1]['Town_City'],\n",
        "            'District': data[1][-1]['District'],\n",
        "            'County': data[1][-1]['County']\n",
        "        }\n",
        "        transaction_data = []\n",
        "        for transaction in data[1]:\n",
        "            transaction_data.append({\n",
        "                'PropertyID': property_id,\n",
        "                'Tran_uid': transaction['Tran_uid'],\n",
        "                'Price': transaction['Price'],\n",
        "                'Date_Tran': transaction['Date_tran'],\n",
        "                'PType': transaction['PType'],\n",
        "                'Old_New': transaction['Old_New'],\n",
        "                'Duration': transaction['Duration'],\n",
        "                'PPD_cat': transaction['PPD_cat'],\n",
        "                'Record_stat': transaction['Record_stat']\n",
        "            })\n",
        "\n",
        "        yield property_data\n",
        "        for transaction in transaction_data:\n",
        "            yield transaction\n"
      ],
      "metadata": {
        "id": "6rifOfgaDWCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa-xurhQqXox"
      },
      "source": [
        "Initialising a Dictionary to generate property ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r14YjTQAB_zZ"
      },
      "outputs": [],
      "source": [
        "dict_post={}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSGSAcp_qfSz"
      },
      "source": [
        "I decided to use the first half of the post code for generating unique property ID. for each of these codes, count of property was and appended to give the final Property ID  \n",
        "\n",
        "The below function describes the process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c55w-7xZHJpD"
      },
      "outputs": [],
      "source": [
        "def propkeyid_gen(postcode):\n",
        "    global dict_post\n",
        "    split_c = postcode\n",
        "    \n",
        "    if split_c in dict_post:\n",
        "        dict_post[split_c] += 1\n",
        "    else:\n",
        "        dict_post[split_c] = 1\n",
        "    \n",
        "    count_postc = dict_post[split_c]\n",
        "    num = str(count_postc).zfill(4)\n",
        "    \n",
        "    property_key=Split_c+'-'+num\n",
        "    return property_key\n",
        "\n",
        "#We are using the first half of postcode for generating the property key"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formatting the grouped data to NDJSON format to be then stored in MongoDB Atlas"
      ],
      "metadata": {
        "id": "83XQbVLzOSu8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8WfLCljUURY"
      },
      "outputs": [],
      "source": [
        "class FormatInfo(beam.DoFn):\n",
        "    def process(self, data):\n",
        "\n",
        "        property_id = propkeyid_gen(data[0].split(',')[-1])  # Generate property ID\n",
        "        \n",
        "        property_data = {\n",
        "            'PropertyID': property_id,\n",
        "            'Postcode': data[1][-1]['Postcode'],\n",
        "            'PAON': data[0].split(',')[0],\n",
        "            'SAON': data[0].split(',')[1],\n",
        "            'Street': data[0].split(',')[2],\n",
        "            'Locality': data[0].split(',')[3],\n",
        "            'TownCity': data[1][-1]['Town_City'],\n",
        "            'District': data[1][-1]['District'],\n",
        "            'County': data[1][-1]['County']\n",
        "        }\n",
        "        transaction_data = []\n",
        "        for transaction in data[1]:\n",
        "            transaction_data.append({\n",
        "                'PropertyID': property_id,\n",
        "                'Tran_uid': transaction['Tran_uid'],\n",
        "                'Price': transaction['Price'],\n",
        "                'Date_Tran': transaction['Date_tran'],\n",
        "                'PType': transaction['PType'],\n",
        "                'Old_New': transaction['Old_New'],\n",
        "                'Duration': transaction['Duration'],\n",
        "                'PPD_cat': transaction['PPD_cat'],\n",
        "                'Record_stat': transaction['Record_stat']\n",
        "            })\n",
        "        \n",
        "        yield property_data\n",
        "        for transaction in transaction_data:\n",
        "            yield transaction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdkGVlWYoHyC"
      },
      "source": [
        "***Pipeline Code Block***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline(options=options_aws) as p:\n",
        "    # Read the input CSV file\n",
        "    lines = p | ReadFromText('s3://bvkawsbucket/pp-complete.csv')\n",
        "    properties = (\n",
        "        lines\n",
        "        | 'Parse CSV Lines' >> beam.Map(parse_csv_line)\n",
        "        | 'Filtering Data' >> beam.Filter(lambda x: x[12] == 'BIRMINGHAM') #Only a subset of the entire Data \n",
        "        | 'Key-Value Gen' >> beam.ParDo(ExtractInfo())\n",
        "        | 'Aggregating the Data' >> beam.GroupByKey()\n",
        "        | 'Formating the Data' >> beam.ParDo(FormatInfo()))\n",
        "    \n",
        "    property_data = (properties \n",
        "    | beam.Filter(lambda x: 'Tran_uid' not in x)\n",
        "    | 'Loading Property Data' >> WriteToMongoDB(uri=connection_uri, db=\"propertyuk\", coll=\"bham_prop\"))\n",
        "    \n",
        "    transaction_data = (properties \n",
        "    | beam.Filter(lambda x: 'Tran_uid' in x)\n",
        "    | 'Loading Transaction Data' >> WriteToMongoDB(uri=connection_uri, db=\"propertyuk\", coll=\"bham_tran\"))"
      ],
      "metadata": {
        "id": "4ZAY5XLjbmSF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}